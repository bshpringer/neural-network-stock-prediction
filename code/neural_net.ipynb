{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Stock Price Movement with a Feed Forward Neural Network, using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate our model, we split the the 186k events of 1/6/17 such that we train on the first 80% of the day, and validate using the final 20%. After tuning parameters, we use the entire 1/6/17 data set to train, and then test using the following day's data, which is from 1/9/17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first 1000 and last 1000 events due to weirdness from the beginning and end of the trading day.\n",
    "train = pd.read_csv('../SOXX_01_06_processed.csv')\n",
    "train_data = train[1000:-1000].reset_index(drop=True)\n",
    "\n",
    "test = pd.read_csv('../SOXX_01_09_processed.csv')\n",
    "test_data = test[1000:-1000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Standardizing Features and Encoding Labels\n",
    "Use sklearn prepocessing module to both encode labels, and standard scale the columns for the train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "bid_columns = []\n",
    "ask_columns = []\n",
    "\n",
    "for i in range(10, 0, -1):\n",
    "    bid_columns.append('bid' + str(i))\n",
    "\n",
    "for i in range(1,11):\n",
    "    ask_columns.append('ask' + str(i))\n",
    "\n",
    "train_depths = train_data[bid_columns + ask_columns]\n",
    "test_depths = test_data[bid_columns + ask_columns]\n",
    "depth_names = train_depths.columns\n",
    "\n",
    "scaled_depths = scaler.fit_transform(train_depths)\n",
    "train_x = pd.DataFrame(scaled_depths, columns=depth_names)\n",
    "train_x['normalized_mid_price'] = train_data.norm_mid_price\n",
    "train_x['mid_price_change'] = train_data.norm_mid_price_change\n",
    "train_x['normalized_relative_depth'] = train_data.norm_rel_depth\n",
    "\n",
    "scaled_test_depths = scaler.fit_transform(test_depths)\n",
    "test_x = pd.DataFrame(scaled_test_depths, columns=depth_names)\n",
    "test_x['normalized_mid_price'] = test_data.norm_mid_price\n",
    "test_x['mid_price_change'] = test_data.norm_mid_price_change\n",
    "test_x['normalized_relative_depth'] = test_data.norm_rel_depth\n",
    "\n",
    "train_set_x = train_x[:150000]\n",
    "validation_x = train_x[150000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the input columns look good and standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid10</th>\n",
       "      <th>bid9</th>\n",
       "      <th>bid8</th>\n",
       "      <th>bid7</th>\n",
       "      <th>bid6</th>\n",
       "      <th>bid5</th>\n",
       "      <th>bid4</th>\n",
       "      <th>bid3</th>\n",
       "      <th>bid2</th>\n",
       "      <th>bid1</th>\n",
       "      <th>...</th>\n",
       "      <th>ask4</th>\n",
       "      <th>ask5</th>\n",
       "      <th>ask6</th>\n",
       "      <th>ask7</th>\n",
       "      <th>ask8</th>\n",
       "      <th>ask9</th>\n",
       "      <th>ask10</th>\n",
       "      <th>normalized_mid_price</th>\n",
       "      <th>mid_price_change</th>\n",
       "      <th>normalized_relative_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>-0.916484</td>\n",
       "      <td>0.469729</td>\n",
       "      <td>-0.763767</td>\n",
       "      <td>0.172598</td>\n",
       "      <td>-0.578536</td>\n",
       "      <td>-0.742413</td>\n",
       "      <td>-1.439773</td>\n",
       "      <td>-0.087217</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>-0.754155</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.813906</td>\n",
       "      <td>-1.779646</td>\n",
       "      <td>-1.305669</td>\n",
       "      <td>-0.946409</td>\n",
       "      <td>-0.962680</td>\n",
       "      <td>-0.949827</td>\n",
       "      <td>-0.346373</td>\n",
       "      <td>-1.427243</td>\n",
       "      <td>1.140265</td>\n",
       "      <td>2.694120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>-0.916484</td>\n",
       "      <td>0.469729</td>\n",
       "      <td>-0.763767</td>\n",
       "      <td>0.172598</td>\n",
       "      <td>-0.578536</td>\n",
       "      <td>-0.742413</td>\n",
       "      <td>-1.439773</td>\n",
       "      <td>-0.087217</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>-0.754155</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.813906</td>\n",
       "      <td>-1.779646</td>\n",
       "      <td>-1.305700</td>\n",
       "      <td>-0.946599</td>\n",
       "      <td>-0.617941</td>\n",
       "      <td>-0.949870</td>\n",
       "      <td>-0.924091</td>\n",
       "      <td>-1.427243</td>\n",
       "      <td>1.140265</td>\n",
       "      <td>2.694462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>-0.916484</td>\n",
       "      <td>0.469729</td>\n",
       "      <td>-0.763767</td>\n",
       "      <td>0.172598</td>\n",
       "      <td>-0.578536</td>\n",
       "      <td>-0.742413</td>\n",
       "      <td>-1.439773</td>\n",
       "      <td>-0.087217</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>-0.754155</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.813906</td>\n",
       "      <td>-1.779646</td>\n",
       "      <td>-1.305700</td>\n",
       "      <td>-0.946599</td>\n",
       "      <td>-0.617941</td>\n",
       "      <td>-0.949870</td>\n",
       "      <td>-0.924091</td>\n",
       "      <td>-1.427243</td>\n",
       "      <td>1.140265</td>\n",
       "      <td>2.694462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>-0.916484</td>\n",
       "      <td>0.469729</td>\n",
       "      <td>-0.763767</td>\n",
       "      <td>0.172598</td>\n",
       "      <td>-0.578536</td>\n",
       "      <td>-0.742413</td>\n",
       "      <td>-1.439773</td>\n",
       "      <td>-0.087217</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>-0.754155</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.813906</td>\n",
       "      <td>-1.779646</td>\n",
       "      <td>-1.305700</td>\n",
       "      <td>-0.946599</td>\n",
       "      <td>-0.617941</td>\n",
       "      <td>-0.949870</td>\n",
       "      <td>-0.924091</td>\n",
       "      <td>-1.427243</td>\n",
       "      <td>1.140265</td>\n",
       "      <td>3.329511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>-0.916484</td>\n",
       "      <td>0.469729</td>\n",
       "      <td>-0.763767</td>\n",
       "      <td>0.172598</td>\n",
       "      <td>-0.578536</td>\n",
       "      <td>-0.742413</td>\n",
       "      <td>-1.439773</td>\n",
       "      <td>-0.087217</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>-0.754155</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.243165</td>\n",
       "      <td>-1.779646</td>\n",
       "      <td>-1.305700</td>\n",
       "      <td>-0.946599</td>\n",
       "      <td>-0.617941</td>\n",
       "      <td>-0.949870</td>\n",
       "      <td>-0.924091</td>\n",
       "      <td>-1.427243</td>\n",
       "      <td>1.140265</td>\n",
       "      <td>2.694369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>-0.916484</td>\n",
       "      <td>0.469729</td>\n",
       "      <td>-0.763767</td>\n",
       "      <td>0.172598</td>\n",
       "      <td>-0.578536</td>\n",
       "      <td>-0.742413</td>\n",
       "      <td>-1.439773</td>\n",
       "      <td>-0.087217</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>-0.754155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.862671</td>\n",
       "      <td>-1.779646</td>\n",
       "      <td>-1.305700</td>\n",
       "      <td>-0.946599</td>\n",
       "      <td>-0.617941</td>\n",
       "      <td>-0.949870</td>\n",
       "      <td>-0.924091</td>\n",
       "      <td>-1.427243</td>\n",
       "      <td>1.140265</td>\n",
       "      <td>2.339232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>-0.916484</td>\n",
       "      <td>0.469729</td>\n",
       "      <td>-0.763767</td>\n",
       "      <td>0.172598</td>\n",
       "      <td>-0.578536</td>\n",
       "      <td>-0.742413</td>\n",
       "      <td>-1.439773</td>\n",
       "      <td>-0.087217</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>-0.754155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.862671</td>\n",
       "      <td>-1.779646</td>\n",
       "      <td>-1.305700</td>\n",
       "      <td>-0.946599</td>\n",
       "      <td>-0.617941</td>\n",
       "      <td>-0.949870</td>\n",
       "      <td>-0.924091</td>\n",
       "      <td>-1.427243</td>\n",
       "      <td>1.306359</td>\n",
       "      <td>2.339232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>0.987799</td>\n",
       "      <td>-0.475337</td>\n",
       "      <td>0.863938</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>-0.350305</td>\n",
       "      <td>-1.189503</td>\n",
       "      <td>0.040080</td>\n",
       "      <td>-0.087016</td>\n",
       "      <td>-1.386611</td>\n",
       "      <td>-0.754155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.862671</td>\n",
       "      <td>-1.779646</td>\n",
       "      <td>-1.305700</td>\n",
       "      <td>-0.946599</td>\n",
       "      <td>-0.617941</td>\n",
       "      <td>-0.949870</td>\n",
       "      <td>-0.924091</td>\n",
       "      <td>-1.427243</td>\n",
       "      <td>1.306359</td>\n",
       "      <td>2.516934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>0.987799</td>\n",
       "      <td>-0.475337</td>\n",
       "      <td>0.863938</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>-0.350305</td>\n",
       "      <td>-1.189503</td>\n",
       "      <td>-0.382710</td>\n",
       "      <td>-0.087016</td>\n",
       "      <td>-1.386611</td>\n",
       "      <td>-0.754155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.862671</td>\n",
       "      <td>-1.779646</td>\n",
       "      <td>-1.305700</td>\n",
       "      <td>-0.946599</td>\n",
       "      <td>-0.617941</td>\n",
       "      <td>-0.949870</td>\n",
       "      <td>-0.924091</td>\n",
       "      <td>-1.427243</td>\n",
       "      <td>1.472468</td>\n",
       "      <td>2.339333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>0.987799</td>\n",
       "      <td>-0.475337</td>\n",
       "      <td>0.863938</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>-0.350305</td>\n",
       "      <td>-1.189503</td>\n",
       "      <td>-0.382710</td>\n",
       "      <td>-0.087016</td>\n",
       "      <td>-1.386611</td>\n",
       "      <td>-0.754155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.862671</td>\n",
       "      <td>-1.779646</td>\n",
       "      <td>-1.305700</td>\n",
       "      <td>-0.946599</td>\n",
       "      <td>-0.617941</td>\n",
       "      <td>-0.949870</td>\n",
       "      <td>-0.924091</td>\n",
       "      <td>-1.427243</td>\n",
       "      <td>1.472468</td>\n",
       "      <td>2.339333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          bid10      bid9      bid8      bid7      bid6      bid5      bid4  \\\n",
       "10000 -0.916484  0.469729 -0.763767  0.172598 -0.578536 -0.742413 -1.439773   \n",
       "10001 -0.916484  0.469729 -0.763767  0.172598 -0.578536 -0.742413 -1.439773   \n",
       "10002 -0.916484  0.469729 -0.763767  0.172598 -0.578536 -0.742413 -1.439773   \n",
       "10003 -0.916484  0.469729 -0.763767  0.172598 -0.578536 -0.742413 -1.439773   \n",
       "10004 -0.916484  0.469729 -0.763767  0.172598 -0.578536 -0.742413 -1.439773   \n",
       "10005 -0.916484  0.469729 -0.763767  0.172598 -0.578536 -0.742413 -1.439773   \n",
       "10006 -0.916484  0.469729 -0.763767  0.172598 -0.578536 -0.742413 -1.439773   \n",
       "10007  0.987799 -0.475337  0.863938 -0.076316 -0.350305 -1.189503  0.040080   \n",
       "10008  0.987799 -0.475337  0.863938 -0.076316 -0.350305 -1.189503 -0.382710   \n",
       "10009  0.987799 -0.475337  0.863938 -0.076316 -0.350305 -1.189503 -0.382710   \n",
       "\n",
       "           bid3      bid2      bid1  ...      ask4      ask5      ask6  \\\n",
       "10000 -0.087217  0.251144 -0.754155  ... -1.813906 -1.779646 -1.305669   \n",
       "10001 -0.087217  0.251144 -0.754155  ... -1.813906 -1.779646 -1.305700   \n",
       "10002 -0.087217  0.251144 -0.754155  ... -1.813906 -1.779646 -1.305700   \n",
       "10003 -0.087217  0.251144 -0.754155  ... -1.813906 -1.779646 -1.305700   \n",
       "10004 -0.087217  0.251144 -0.754155  ... -1.243165 -1.779646 -1.305700   \n",
       "10005 -0.087217  0.251144 -0.754155  ... -0.862671 -1.779646 -1.305700   \n",
       "10006 -0.087217  0.251144 -0.754155  ... -0.862671 -1.779646 -1.305700   \n",
       "10007 -0.087016 -1.386611 -0.754155  ... -0.862671 -1.779646 -1.305700   \n",
       "10008 -0.087016 -1.386611 -0.754155  ... -0.862671 -1.779646 -1.305700   \n",
       "10009 -0.087016 -1.386611 -0.754155  ... -0.862671 -1.779646 -1.305700   \n",
       "\n",
       "           ask7      ask8      ask9     ask10  normalized_mid_price  \\\n",
       "10000 -0.946409 -0.962680 -0.949827 -0.346373             -1.427243   \n",
       "10001 -0.946599 -0.617941 -0.949870 -0.924091             -1.427243   \n",
       "10002 -0.946599 -0.617941 -0.949870 -0.924091             -1.427243   \n",
       "10003 -0.946599 -0.617941 -0.949870 -0.924091             -1.427243   \n",
       "10004 -0.946599 -0.617941 -0.949870 -0.924091             -1.427243   \n",
       "10005 -0.946599 -0.617941 -0.949870 -0.924091             -1.427243   \n",
       "10006 -0.946599 -0.617941 -0.949870 -0.924091             -1.427243   \n",
       "10007 -0.946599 -0.617941 -0.949870 -0.924091             -1.427243   \n",
       "10008 -0.946599 -0.617941 -0.949870 -0.924091             -1.427243   \n",
       "10009 -0.946599 -0.617941 -0.949870 -0.924091             -1.427243   \n",
       "\n",
       "       mid_price_change  normalized_relative_depth  \n",
       "10000          1.140265                   2.694120  \n",
       "10001          1.140265                   2.694462  \n",
       "10002          1.140265                   2.694462  \n",
       "10003          1.140265                   3.329511  \n",
       "10004          1.140265                   2.694369  \n",
       "10005          1.140265                   2.339232  \n",
       "10006          1.306359                   2.339232  \n",
       "10007          1.306359                   2.516934  \n",
       "10008          1.472468                   2.339333  \n",
       "10009          1.472468                   2.339333  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_x[10000:10010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "train_y = train_data['change_label']\n",
    "le.fit(train_y)\n",
    "encoded_train_y = le.transform(train_y)\n",
    "encoded_train_set_y = encoded_train_y[:150000]\n",
    "encoded_validation_set_y = encoded_train_y[150000:]\n",
    "\n",
    "test_y = test_data['change_label']\n",
    "encoded_test_y = le.transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Layer Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = len(train_x.columns)\n",
    "n_hidden1 = 13\n",
    "n_hidden2 = 8\n",
    "n_outputs = 3\n",
    "num_examples = len(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up placeholders and  2 hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-775e13366fdd>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Users/Beni/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x_place = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"x_place\")\n",
    "y_place = tf.placeholder(tf.int32, shape=(None), name=\"y_place\")\n",
    "\n",
    "layer1 = tf.layers.dense(x_place, n_hidden1, activation = tf.nn.relu, name = 'hidden1')\n",
    "layer2 = tf.layers.dense(layer1, n_hidden2, activation = tf.nn.relu, name = 'hidden2')\n",
    "logits = tf.layers.dense(layer2, n_outputs, name = 'outputs')\n",
    "\n",
    "predictions = tf.nn.softmax(logits, name = 'predictions') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a loss function: softmax cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_place, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    loss_summary = tf.summary.scalar('log_loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define an optimization method: AdamOptimizer with .0001 learn rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define an accuracy metric: did the neural network predict the correct label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y_place, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net Iteration\n",
    "* Define epoch and batch_size parameters\n",
    "* Instantiate variables and a saver to save the model\n",
    "\n",
    "* We want to train sequentially, thus, for each iteration, we keep track of the current index,  increment by the batch size.\n",
    "* We train on the batch, then change the start index such that we train on the next sequential batch\n",
    "* Save and print results every 50 epochs to see the average accuracy and loss for that epoch.\n",
    "* Finally save the model after all epochs have completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import datetime\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 500\n",
    "\n",
    "num_examples = len(train_x)\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    writer = tf.summary.FileWriter('./graphs/', sess.graph)\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_acc = 0\n",
    "        epoch_loss = 0\n",
    "        iterations = 0\n",
    "        current_index = 0\n",
    "        for iteration in range(num_examples // batch_size):\n",
    "            next_index = current_index + batch_size\n",
    "            x_batch = train_x[current_index:next_index]\n",
    "            y_batch = encoded_train_y[current_index:next_index]\n",
    "            sess.run(training_op, feed_dict = {x_place:x_batch, y_place:y_batch})\n",
    "            current_index = next_index\n",
    "            acc_batch = accuracy.eval(feed_dict={x_place: x_batch, y_place: y_batch})\n",
    "            loss_batch = loss.eval(feed_dict={x_place: x_batch, y_place: y_batch})\n",
    "            \n",
    "            if (epoch+1) % 50 == 0:\n",
    "                acc_batch = accuracy.eval(feed_dict={x_place: x_batch, y_place: y_batch})\n",
    "                loss_batch = loss.eval(feed_dict={x_place: x_batch, y_place: y_batch})\n",
    "                epoch_acc = epoch_acc + acc_batch\n",
    "                epoch_loss = epoch_loss + loss_batch\n",
    "                iterations += 1\n",
    "            \n",
    "        if (epoch+1) % 50 == 0:\n",
    "            acc_train = accuracy.eval(feed_dict = {x_place: x_batch, y_place:y_batch})\n",
    "            summary1, summary2 = sess.run([loss_summary, accuracy_summary], feed_dict = {x_place: train_x, y_place:encoded_train_y})\n",
    "            \n",
    "            writer.add_summary(summary1, epoch+1)\n",
    "            writer.add_summary(summary2, epoch+1)\n",
    "            print(datetime.datetime.now())\n",
    "            print(epoch+1)\n",
    "            print(\"Epoch acc: \"+ str(epoch_acc/iterations))\n",
    "            print(\"Epoch loss: \"+ str(epoch_loss/iterations))\n",
    "            \n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final20.ckpt\")\n",
    "    Z = logits.eval(feed_dict = {x_place: test_x})\n",
    "    y_pred= np.argmax(Z, axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
